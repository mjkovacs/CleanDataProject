# README

## Overview
This repo is for the Getting & Cleaning project.

### Project Assignment:  
https://class.coursera.org/getdata-032/human_grading/view/courses/975116/assessments/3/submissions

### Data Source: 
https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip 

### Project Objectives
1. Merges the training and the test sets to create one data set.
2. Extracts only the measurements on the mean and standard deviation for each measurement. 
3. Uses descriptive activity names to name the activities in the data set
4. Appropriately labels the data set with descriptive variable names. 
5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

### Files
1. CodeBook.md : Describes each variable in the output file generated by running the R script.
2. TidySum.txt : The name of the file generated by running the R script.
3. README.md : This file
4. run_analysis.R : The R script

Before running the script, the data must be downloaded and decompressed in location of the R script.  Decompressing the download should create the subfolder ‘UCI HAR Dataset’.  In the ‘UCI HAR Dataset’ folder a README file describes the each of the dataset files and contents.


## Approach for the R Script
At a high level, instead of utilizing pipes or nesting steps, I decided to keep them as single statements to make the review easy.

### Objective 1 & 2
Looking at the project objectives 1 & 2, loading in Inertial Signals data for objective 1 was not done as they would need to be stripped out for objective 2.

The first step was to read each of the text files (see R script). The activity_labels.txt and features.txt contained data that applied to both the test and train datasets. 

For the Features, we only wanted to extract those variables in the X_test and X_train files where the Feature was either ‘mean()’ or ‘std()’ (see R script dt.ColumnsNeeded).   

Next, the data files in the test folder is read and merged (cbind) followed by the train folder. When the X_test.txt and X_train.txt files where read, we used dt.ColumnsNeeded to both identify and label the variables in resulting data frame

After reading in the test and train files, they are merged (rbind) into one data frame 'df.AllData’. Finally, the activity_id was used to link the activity_desc and then the activity_id was removed. 

### Objective 3
only to strip them out for objective 2 wa and the data files, it was determined that 	

### Objective 4
After reading in the X_test.txt and X_train.txt files dt.ColumnsNeeded was used to apply the variable names subsetted from features.txt.

### Objective 5
The merged data files (df.AlLData) was melted based on subject_id + activity_desc and variable and the mean function was used for the values.  This would result an observation for each subject_id, each activity_desc, each variable (i.e. a feature containing mean() or std()) and a value.

Next, it was reshaped using dcast to result in a wide set and written to a text file ’TidySum.txt’.  The final data frame is 180 observations ( 30 subjects * 6 activities ) and 81 variables (subject_id, activity_desc, and 79 features containing mean() or std().
	
  
	